{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMOOJWYs2AUYQxpimACO6mD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Twinkle-gawri/Word2Vec/blob/main/Extrinsic_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXTRINSIC EVALUATION\n",
        "Evaluating by using it inside a real-world task and checking performance.\n",
        "\n",
        "Real tasks could be:\n",
        "* Sentiment analysis\n",
        "* Text classification\n",
        "* Machine translation\n",
        "* Question answering\n",
        "* Information retrieval"
      ],
      "metadata": {
        "id": "5Xmu7K5ABeQP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7zUSt1w_gMIG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential,layers\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.datasets import imdb\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqOKQvmFgO3N",
        "outputId": "12d0c0d4-019e-44ac-9421-6d6e5d0412b5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import downloader"
      ],
      "metadata": {
        "id": "-cFmlL6HgQo2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wv=downloader.load('word2vec-google-news-300')"
      ],
      "metadata": {
        "id": "nQ1LyLwpgTgo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test,y_test)=imdb.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCAvricHgVo_",
        "outputId": "9bc387d9-c847-40ea-d3f3-19c5419e2995"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWni6vTdgY_s",
        "outputId": "d0d62098-1852-4d8c-8519-8cf444d93eef"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 22665,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 21631,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 19193,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 10311,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 31050,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 12118,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2index=imdb.get_word_index() # converts words -> indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_XtHGRYiPw9",
        "outputId": "7649d86c-321d-4310-a92a-0038a73d5b42"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index2word={index:word for word,index in word2index.items()} # converts indices -> words"
      ],
      "metadata": {
        "id": "pP9DYoiaiYc8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_review(encoded_review):\n",
        "  return ' '.join([index2word.get(i,\"?\") for i in encoded_review])   # Uses index2word.get(i, \"?\") to convert each index back to its corresponding word.\n",
        "                                # If the index i isn’t found in the dictionary (e.g., it's an unknown word), it returns \"?\"."
      ],
      "metadata": {
        "id": "2XffthSHier9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_text = [decode_review(encoded_review) for encoded_review in x_train] # converting the lists present into x_train into human readable form\n",
        "x_test_text = [decode_review(encoded_review) for encoded_review in x_test]"
      ],
      "metadata": {
        "id": "zN-CdtaFlpml"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_embeddings(sentence):\n",
        "  words=sentence.split()\n",
        "  vectors=[wv[word] for word in words if word in wv.key_to_index]  # wv.key_to_index is a dictionary of all the words in the embedding model.\n",
        "  return np.mean(vectors, axis=0) if vectors else np.zeros(300) # computes the mean of all word vectors in the sentence - averaging across each dimension of the word vectors"
      ],
      "metadata": {
        "id": "P5hm4k84mc_d"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_embeddings=np.array([sentence_embeddings(sentence) for sentence in x_train_text])\n",
        "\n",
        "test_embeddings=np.array([sentence_embeddings(sentence) for sentence in x_test_text])"
      ],
      "metadata": {
        "id": "PhN8XDK3q6w9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Takes in pairs of data and labels.\n",
        "Creates a dataset where each item looks like (embedding, label).\n",
        "\"\"\"\n",
        "train_dataset=tf.data.Dataset.from_tensor_slices((train_embeddings,y_train)).batch(32)\n",
        "test_dataset=tf.data.Dataset.from_tensor_slices((test_embeddings,y_test)).batch(32)"
      ],
      "metadata": {
        "id": "Iu2mgAAbrDjQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential(\n",
        "    [\n",
        "        layers.Input(shape=(300,)),\n",
        "        Dense(256,activation='relu'),\n",
        "        Dense(128,activation='relu'),\n",
        "        Dense(1,activation='sigmoid')\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "zdLefMZWr5Yq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=keras.losses.BinaryCrossentropy(3e-4),\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Bjn45l1zsZ12"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset,validation_data=test_dataset,epochs=20,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgRnK0I3sl_e",
        "outputId": "db3466bd-84d6-41dd-cc17-c8a7930b4d18"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/nn.py:780: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5539 - loss: 0.6757 - val_accuracy: 0.6807 - val_loss: 0.5992\n",
            "Epoch 2/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6788 - loss: 0.5980 - val_accuracy: 0.7017 - val_loss: 0.5769\n",
            "Epoch 3/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7002 - loss: 0.5781 - val_accuracy: 0.7052 - val_loss: 0.5687\n",
            "Epoch 4/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7035 - loss: 0.5709 - val_accuracy: 0.7102 - val_loss: 0.5639\n",
            "Epoch 5/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7053 - loss: 0.5686 - val_accuracy: 0.7152 - val_loss: 0.5609\n",
            "Epoch 6/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7046 - loss: 0.5662 - val_accuracy: 0.7143 - val_loss: 0.5604\n",
            "Epoch 7/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7084 - loss: 0.5624 - val_accuracy: 0.7163 - val_loss: 0.5580\n",
            "Epoch 8/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7116 - loss: 0.5588 - val_accuracy: 0.7148 - val_loss: 0.5613\n",
            "Epoch 9/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7153 - loss: 0.5564 - val_accuracy: 0.7169 - val_loss: 0.5586\n",
            "Epoch 10/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7179 - loss: 0.5535 - val_accuracy: 0.7159 - val_loss: 0.5586\n",
            "Epoch 11/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7211 - loss: 0.5503 - val_accuracy: 0.7129 - val_loss: 0.5604\n",
            "Epoch 12/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7217 - loss: 0.5488 - val_accuracy: 0.7117 - val_loss: 0.5637\n",
            "Epoch 13/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7265 - loss: 0.5457 - val_accuracy: 0.7130 - val_loss: 0.5623\n",
            "Epoch 14/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7261 - loss: 0.5437 - val_accuracy: 0.7145 - val_loss: 0.5614\n",
            "Epoch 15/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7276 - loss: 0.5411 - val_accuracy: 0.7115 - val_loss: 0.5656\n",
            "Epoch 16/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7311 - loss: 0.5383 - val_accuracy: 0.7070 - val_loss: 0.5695\n",
            "Epoch 17/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7331 - loss: 0.5348 - val_accuracy: 0.7050 - val_loss: 0.5719\n",
            "Epoch 18/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7334 - loss: 0.5325 - val_accuracy: 0.7064 - val_loss: 0.5699\n",
            "Epoch 19/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7353 - loss: 0.5306 - val_accuracy: 0.7091 - val_loss: 0.5685\n",
            "Epoch 20/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7371 - loss: 0.5273 - val_accuracy: 0.7070 - val_loss: 0.5699\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e09e48fd990>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using TensorFlow Hub Universal Sentence Encoder\n",
        "It converts entire sentences (or paragraphs) into embeddings that capture the meaning of the sentence."
      ],
      "metadata": {
        "id": "YDKTZuYupLJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
      ],
      "metadata": {
        "id": "bJC3k_cOubvI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "FWXNJGInplP2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "\n",
        "# Batch size for processing the data\n",
        "batch_size = 32\n",
        "\n",
        "def embed_in_batches(texts, batch_size):\n",
        "  \"\"\"converts a big list of sentences into sentence embeddings, but processes them in smaller batches (instead of all at once)train_embeddings_1.shape.\"\"\"\n",
        "  all_embeddings = []\n",
        "  for i in range(0, len(texts), batch_size):\n",
        "    batch_embeddings = embed(texts[i : i + batch_size])\n",
        "    all_embeddings.extend(batch_embeddings)\n",
        "  return np.array(all_embeddings)\n",
        "\n",
        "# Embed the training and test data in batches\n",
        "train_embeddings_1 = embed_in_batches(x_train_text, batch_size)\n",
        "test_embeddings_1 = embed_in_batches(x_test_text, batch_size)"
      ],
      "metadata": {
        "id": "75GONRw0pXIN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_embeddings_1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5auDCVB5pp9s",
        "outputId": "b2a62bf4-595a-4a1f-b3f8-b24576ea981a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1=Sequential(\n",
        "    [\n",
        "        layers.Input(shape=(512,)),\n",
        "        Dense(256,activation='relu'),\n",
        "        Dense(128,activation='relu'),\n",
        "        Dense(1,activation='sigmoid')\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "jYX7jEVpusVl"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(loss=keras.losses.BinaryCrossentropy(3e-4),\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "77hAtpV_vZsI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit(train_embeddings_1,y_train,validation_data=(test_embeddings_1,y_test),batch_size=32,epochs=20,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtgN9O9tvnt7",
        "outputId": "7e23b976-965e-4167-a940-3c7f2e2e8105"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/nn.py:780: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.6058 - loss: 0.6519 - val_accuracy: 0.6582 - val_loss: 0.6145\n",
            "Epoch 2/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.6599 - loss: 0.6106 - val_accuracy: 0.6627 - val_loss: 0.6115\n",
            "Epoch 3/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6718 - loss: 0.5993 - val_accuracy: 0.6540 - val_loss: 0.6242\n",
            "Epoch 4/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6898 - loss: 0.5821 - val_accuracy: 0.6674 - val_loss: 0.6111\n",
            "Epoch 5/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7050 - loss: 0.5611 - val_accuracy: 0.6557 - val_loss: 0.6243\n",
            "Epoch 6/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7347 - loss: 0.5270 - val_accuracy: 0.6592 - val_loss: 0.6431\n",
            "Epoch 7/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7618 - loss: 0.4921 - val_accuracy: 0.6545 - val_loss: 0.7002\n",
            "Epoch 8/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7915 - loss: 0.4407 - val_accuracy: 0.6444 - val_loss: 0.7541\n",
            "Epoch 9/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8162 - loss: 0.3989 - val_accuracy: 0.6443 - val_loss: 0.7952\n",
            "Epoch 10/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8392 - loss: 0.3544 - val_accuracy: 0.6470 - val_loss: 0.8640\n",
            "Epoch 11/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8575 - loss: 0.3140 - val_accuracy: 0.6369 - val_loss: 0.9683\n",
            "Epoch 12/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8800 - loss: 0.2722 - val_accuracy: 0.6371 - val_loss: 1.0445\n",
            "Epoch 13/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9010 - loss: 0.2364 - val_accuracy: 0.6382 - val_loss: 1.1611\n",
            "Epoch 14/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9107 - loss: 0.2107 - val_accuracy: 0.6264 - val_loss: 1.2611\n",
            "Epoch 15/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9261 - loss: 0.1854 - val_accuracy: 0.6330 - val_loss: 1.3575\n",
            "Epoch 16/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9351 - loss: 0.1614 - val_accuracy: 0.6263 - val_loss: 1.6215\n",
            "Epoch 17/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9436 - loss: 0.1400 - val_accuracy: 0.6286 - val_loss: 1.6191\n",
            "Epoch 18/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9481 - loss: 0.1302 - val_accuracy: 0.6254 - val_loss: 1.7747\n",
            "Epoch 19/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9523 - loss: 0.1163 - val_accuracy: 0.6300 - val_loss: 1.8779\n",
            "Epoch 20/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9557 - loss: 0.1134 - val_accuracy: 0.6213 - val_loss: 2.0464\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79cc35aef290>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using TensorFlow Hub Embeddings"
      ],
      "metadata": {
        "id": "LzswZWbJzOQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "embedding = hub.load(\"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim-with-oov/1\")"
      ],
      "metadata": {
        "id": "Q3APEXWNv-yp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This function is trying to create a sentence embedding by:\n",
        "  Splitting the sentence into words,\n",
        "  Getting an embedding for each word individually (using a model called embedding),\n",
        "  Then averaging all those word vectors together to form one vector for the sentence.\n",
        "\n",
        "When you call embedding([word]), you get a 2D vector (shape (1, 300) or (1, 512))\n",
        "When you do [0], you convert it into a 1D vector (shape (300,) or (512,)).\n",
        "Model training expects 1D embeddings (not 2D batches) when building a dataset of sentence/word embeddings.\n",
        "\"\"\"\n",
        "\n",
        "def sentence_embeddings1(sentence):\n",
        "  words=sentence.split()\n",
        "  vectors=[embedding([word])[0] for word in words if embedding([word])[0] is not None]\n",
        "  return np.mean(vectors, axis=0) if vectors else np.zeros(300)"
      ],
      "metadata": {
        "id": "RG6TuPktzelq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_embeddings_2 = np.array([sentence_embeddings1(sentence) for sentence in x_train_text])\n",
        "test_embeddings_2 = np.array([sentence_embeddings1(sentence) for sentence in x_test_text])"
      ],
      "metadata": {
        "id": "AaadVeb3HiRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2=Sequential(\n",
        "    [\n",
        "        layers.Input(shape=(20,)),\n",
        "        Dense(256,activation='relu'),\n",
        "        Dense(128,activation='relu'),\n",
        "        Dense(1,activation='sigmoid')\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "Vd89bxcNH1Qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(loss=keras.losses.BinaryCrossentropy(3e-4),\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Ndm-bbOF8Phu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit(train_embeddings_2,y_train,validation_data=(test_embeddings_2,y_test),batch_size=32,epochs=20,verbose=1)"
      ],
      "metadata": {
        "id": "NZf1laW38YVD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}